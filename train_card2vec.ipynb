{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb95b6a8-3e91-4b24-895e-9957f49f8cf7",
   "metadata": {},
   "source": [
    "# train_card2vec\n",
    "\n",
    "This notebook covers the full card2vec workflow for creation of card embeddings including:\n",
    "* Data download\n",
    "* Preprocessing\n",
    "* Model training (creating embeddings)\n",
    "\n",
    "**Before you begin:**\n",
    "1. Clone this repo.\n",
    "2. specify the set you want to work with in the cell below. (Data will be auto downloaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "736315e7-2866-4053-a007-5664679c336b",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_abbreviation = 'ONE' # 3 letter abbreviate for the set to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5685f2a0-9fa2-4d31-920d-1a06dc0d6021",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "import pandas as pd\n",
    "from DeckCorpus import DeckCorpus\n",
    "from LossCallback import LossCallback\n",
    "import SetTools\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30c1bdb5-9d91-4b97-b04c-ed2258792060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# response = requests.get(\"https://api.scryfall.com/cards/search/?q=e=\" + set_abbreviation)\n",
    "# response_json = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b623731f-2583-4215-92bb-d4f1d1abe6e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import json\n",
    "# response_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ef8b4ec-d54b-499f-a2e3-ab0023f763e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('one.json', 'w') as f:\n",
    "#     json.dump(response_json, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed38245d-9282-4ea3-97f7-af03e93b03b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ComputeError",
     "evalue": "Could not parse `<Error><Code>AccessDenied</Code><Message>Access Denied</Message><RequestId>CRDE6SCDRTVQYSMR</RequestId><HostId>ojs4l0Kzt+RUdexslc+sddYYAik/5QO2om1N8qB+kdA9Am3fL0ZhJhqBWR7TjRFxK2yh1/1qvXwMhxAWPSOlVK66VdzYVTQ+</HostId></Error>` as dtype `i32` at column '<?xml version=\"1.0\" encoding=\"UTF-8\"?>' (column number 1).\nThe current offset in the file is 39 bytes.\n\nYou might want to try:\n- increasing `infer_schema_length` (e.g. `infer_schema_length=10000`),\n- specifying correct dtype with the `dtypes` argument\n- setting `ignore_errors` to `True`,\n- adding `<Error><Code>AccessDenied</Code><Message>Access Denied</Message><RequestId>CRDE6SCDRTVQYSMR</RequestId><HostId>ojs4l0Kzt+RUdexslc+sddYYAik/5QO2om1N8qB+kdA9Am3fL0ZhJhqBWR7TjRFxK2yh1/1qvXwMhxAWPSOlVK66VdzYVTQ+</HostId></Error>` to the `null_values` list.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mComputeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\shwes\\Projects\\ML\\mtg deckbuilding\\MTG-card2vec\\train_card2vec.ipynb Cell 7\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/shwes/Projects/ML/mtg%20deckbuilding/MTG-card2vec/train_card2vec.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Please be kind to 17lands servers and don't overuse this. Will skip download if finds existing .gz files\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/shwes/Projects/ML/mtg%20deckbuilding/MTG-card2vec/train_card2vec.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m SetTools\u001b[39m.\u001b[39mdownload_game_data(set_abbreviation)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/shwes/Projects/ML/mtg%20deckbuilding/MTG-card2vec/train_card2vec.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m SetTools\u001b[39m.\u001b[39;49mgz_to_parquet(set_abbreviation) \u001b[39m# convert gzipped csv to parquet\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\shwes\\Projects\\ML\\mtg deckbuilding\\MTG-card2vec\\SetTools.py:176\u001b[0m, in \u001b[0;36mgz_to_parquet\u001b[1;34m(set_abbreviation)\u001b[0m\n\u001b[0;32m    172\u001b[0m dtypes \u001b[39m=\u001b[39m _game_dtypes(data_sample \u001b[39m=\u001b[39m pl\u001b[39m.\u001b[39mread_csv(file_paths[\u001b[39m0\u001b[39m],\n\u001b[0;32m    173\u001b[0m                                         n_rows\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m))\n\u001b[0;32m    175\u001b[0m \u001b[39mwith\u001b[39;00m pl\u001b[39m.\u001b[39mStringCache(): \u001b[39m# use the same stringcache for categorical vars btwn files\u001b[39;00m\n\u001b[1;32m--> 176\u001b[0m     dfs \u001b[39m=\u001b[39m [pl\u001b[39m.\u001b[39;49mread_csv(file, dtypes\u001b[39m=\u001b[39;49mdtypes) \u001b[39mfor\u001b[39;49;00m file \u001b[39min\u001b[39;49;00m file_paths]\n\u001b[0;32m    177\u001b[0m     \u001b[39m#may temporarily double memory usage by concat before write\u001b[39;00m\n\u001b[0;32m    178\u001b[0m     pl\u001b[39m.\u001b[39mconcat(dfs)\u001b[39m.\u001b[39mwrite_parquet(data_folder \u001b[39m+\u001b[39m set_abbreviation \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.parquet\u001b[39m\u001b[39m'\u001b[39m, compression \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39msnappy\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\shwes\\Projects\\ML\\mtg deckbuilding\\MTG-card2vec\\SetTools.py:176\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    172\u001b[0m dtypes \u001b[39m=\u001b[39m _game_dtypes(data_sample \u001b[39m=\u001b[39m pl\u001b[39m.\u001b[39mread_csv(file_paths[\u001b[39m0\u001b[39m],\n\u001b[0;32m    173\u001b[0m                                         n_rows\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m))\n\u001b[0;32m    175\u001b[0m \u001b[39mwith\u001b[39;00m pl\u001b[39m.\u001b[39mStringCache(): \u001b[39m# use the same stringcache for categorical vars btwn files\u001b[39;00m\n\u001b[1;32m--> 176\u001b[0m     dfs \u001b[39m=\u001b[39m [pl\u001b[39m.\u001b[39;49mread_csv(file, dtypes\u001b[39m=\u001b[39;49mdtypes) \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m file_paths]\n\u001b[0;32m    177\u001b[0m     \u001b[39m#may temporarily double memory usage by concat before write\u001b[39;00m\n\u001b[0;32m    178\u001b[0m     pl\u001b[39m.\u001b[39mconcat(dfs)\u001b[39m.\u001b[39mwrite_parquet(data_folder \u001b[39m+\u001b[39m set_abbreviation \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.parquet\u001b[39m\u001b[39m'\u001b[39m, compression \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39msnappy\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\polars\\io\\csv\\functions.py:366\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(source, has_header, columns, new_columns, separator, comment_char, quote_char, skip_rows, dtypes, schema, null_values, missing_utf8_is_empty_string, ignore_errors, try_parse_dates, n_threads, infer_schema_length, batch_size, n_rows, encoding, low_memory, rechunk, use_pyarrow, storage_options, skip_rows_after_header, row_count_name, row_count_offset, sample_size, eol_char, raise_if_empty, truncate_ragged_lines)\u001b[0m\n\u001b[0;32m    354\u001b[0m         dtypes \u001b[39m=\u001b[39m {\n\u001b[0;32m    355\u001b[0m             new_to_current\u001b[39m.\u001b[39mget(column_name, column_name): column_dtype\n\u001b[0;32m    356\u001b[0m             \u001b[39mfor\u001b[39;00m column_name, column_dtype \u001b[39min\u001b[39;00m dtypes\u001b[39m.\u001b[39mitems()\n\u001b[0;32m    357\u001b[0m         }\n\u001b[0;32m    359\u001b[0m \u001b[39mwith\u001b[39;00m _prepare_file_arg(\n\u001b[0;32m    360\u001b[0m     source,\n\u001b[0;32m    361\u001b[0m     encoding\u001b[39m=\u001b[39mencoding,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    364\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mstorage_options,\n\u001b[0;32m    365\u001b[0m ) \u001b[39mas\u001b[39;00m data:\n\u001b[1;32m--> 366\u001b[0m     df \u001b[39m=\u001b[39m pl\u001b[39m.\u001b[39;49mDataFrame\u001b[39m.\u001b[39;49m_read_csv(\n\u001b[0;32m    367\u001b[0m         data,\n\u001b[0;32m    368\u001b[0m         has_header\u001b[39m=\u001b[39;49mhas_header,\n\u001b[0;32m    369\u001b[0m         columns\u001b[39m=\u001b[39;49mcolumns \u001b[39mif\u001b[39;49;00m columns \u001b[39melse\u001b[39;49;00m projection,\n\u001b[0;32m    370\u001b[0m         separator\u001b[39m=\u001b[39;49mseparator,\n\u001b[0;32m    371\u001b[0m         comment_char\u001b[39m=\u001b[39;49mcomment_char,\n\u001b[0;32m    372\u001b[0m         quote_char\u001b[39m=\u001b[39;49mquote_char,\n\u001b[0;32m    373\u001b[0m         skip_rows\u001b[39m=\u001b[39;49mskip_rows,\n\u001b[0;32m    374\u001b[0m         dtypes\u001b[39m=\u001b[39;49mdtypes,\n\u001b[0;32m    375\u001b[0m         schema\u001b[39m=\u001b[39;49mschema,\n\u001b[0;32m    376\u001b[0m         null_values\u001b[39m=\u001b[39;49mnull_values,\n\u001b[0;32m    377\u001b[0m         missing_utf8_is_empty_string\u001b[39m=\u001b[39;49mmissing_utf8_is_empty_string,\n\u001b[0;32m    378\u001b[0m         ignore_errors\u001b[39m=\u001b[39;49mignore_errors,\n\u001b[0;32m    379\u001b[0m         try_parse_dates\u001b[39m=\u001b[39;49mtry_parse_dates,\n\u001b[0;32m    380\u001b[0m         n_threads\u001b[39m=\u001b[39;49mn_threads,\n\u001b[0;32m    381\u001b[0m         infer_schema_length\u001b[39m=\u001b[39;49minfer_schema_length,\n\u001b[0;32m    382\u001b[0m         batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m    383\u001b[0m         n_rows\u001b[39m=\u001b[39;49mn_rows,\n\u001b[0;32m    384\u001b[0m         encoding\u001b[39m=\u001b[39;49mencoding \u001b[39mif\u001b[39;49;00m encoding \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mutf8-lossy\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39melse\u001b[39;49;00m \u001b[39m\"\u001b[39;49m\u001b[39mutf8\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    385\u001b[0m         low_memory\u001b[39m=\u001b[39;49mlow_memory,\n\u001b[0;32m    386\u001b[0m         rechunk\u001b[39m=\u001b[39;49mrechunk,\n\u001b[0;32m    387\u001b[0m         skip_rows_after_header\u001b[39m=\u001b[39;49mskip_rows_after_header,\n\u001b[0;32m    388\u001b[0m         row_count_name\u001b[39m=\u001b[39;49mrow_count_name,\n\u001b[0;32m    389\u001b[0m         row_count_offset\u001b[39m=\u001b[39;49mrow_count_offset,\n\u001b[0;32m    390\u001b[0m         sample_size\u001b[39m=\u001b[39;49msample_size,\n\u001b[0;32m    391\u001b[0m         eol_char\u001b[39m=\u001b[39;49meol_char,\n\u001b[0;32m    392\u001b[0m         raise_if_empty\u001b[39m=\u001b[39;49mraise_if_empty,\n\u001b[0;32m    393\u001b[0m         truncate_ragged_lines\u001b[39m=\u001b[39;49mtruncate_ragged_lines,\n\u001b[0;32m    394\u001b[0m     )\n\u001b[0;32m    396\u001b[0m \u001b[39mif\u001b[39;00m new_columns:\n\u001b[0;32m    397\u001b[0m     \u001b[39mreturn\u001b[39;00m _update_columns(df, new_columns)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\polars\\dataframe\\frame.py:772\u001b[0m, in \u001b[0;36mDataFrame._read_csv\u001b[1;34m(cls, source, has_header, columns, separator, comment_char, quote_char, skip_rows, dtypes, schema, null_values, missing_utf8_is_empty_string, ignore_errors, try_parse_dates, n_threads, infer_schema_length, batch_size, n_rows, encoding, low_memory, rechunk, skip_rows_after_header, row_count_name, row_count_offset, sample_size, eol_char, raise_if_empty, truncate_ragged_lines)\u001b[0m\n\u001b[0;32m    765\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    766\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mcannot use glob patterns and integer based projection as `columns` argument\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    767\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mUse columns: List[str]\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    768\u001b[0m         )\n\u001b[0;32m    770\u001b[0m projection, columns \u001b[39m=\u001b[39m handle_projection_columns(columns)\n\u001b[1;32m--> 772\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_df \u001b[39m=\u001b[39m PyDataFrame\u001b[39m.\u001b[39;49mread_csv(\n\u001b[0;32m    773\u001b[0m     source,\n\u001b[0;32m    774\u001b[0m     infer_schema_length,\n\u001b[0;32m    775\u001b[0m     batch_size,\n\u001b[0;32m    776\u001b[0m     has_header,\n\u001b[0;32m    777\u001b[0m     ignore_errors,\n\u001b[0;32m    778\u001b[0m     n_rows,\n\u001b[0;32m    779\u001b[0m     skip_rows,\n\u001b[0;32m    780\u001b[0m     projection,\n\u001b[0;32m    781\u001b[0m     separator,\n\u001b[0;32m    782\u001b[0m     rechunk,\n\u001b[0;32m    783\u001b[0m     columns,\n\u001b[0;32m    784\u001b[0m     encoding,\n\u001b[0;32m    785\u001b[0m     n_threads,\n\u001b[0;32m    786\u001b[0m     path,\n\u001b[0;32m    787\u001b[0m     dtype_list,\n\u001b[0;32m    788\u001b[0m     dtype_slice,\n\u001b[0;32m    789\u001b[0m     low_memory,\n\u001b[0;32m    790\u001b[0m     comment_char,\n\u001b[0;32m    791\u001b[0m     quote_char,\n\u001b[0;32m    792\u001b[0m     processed_null_values,\n\u001b[0;32m    793\u001b[0m     missing_utf8_is_empty_string,\n\u001b[0;32m    794\u001b[0m     try_parse_dates,\n\u001b[0;32m    795\u001b[0m     skip_rows_after_header,\n\u001b[0;32m    796\u001b[0m     _prepare_row_count_args(row_count_name, row_count_offset),\n\u001b[0;32m    797\u001b[0m     sample_size\u001b[39m=\u001b[39;49msample_size,\n\u001b[0;32m    798\u001b[0m     eol_char\u001b[39m=\u001b[39;49meol_char,\n\u001b[0;32m    799\u001b[0m     raise_if_empty\u001b[39m=\u001b[39;49mraise_if_empty,\n\u001b[0;32m    800\u001b[0m     truncate_ragged_lines\u001b[39m=\u001b[39;49mtruncate_ragged_lines,\n\u001b[0;32m    801\u001b[0m     schema\u001b[39m=\u001b[39;49mschema,\n\u001b[0;32m    802\u001b[0m )\n\u001b[0;32m    803\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "\u001b[1;31mComputeError\u001b[0m: Could not parse `<Error><Code>AccessDenied</Code><Message>Access Denied</Message><RequestId>CRDE6SCDRTVQYSMR</RequestId><HostId>ojs4l0Kzt+RUdexslc+sddYYAik/5QO2om1N8qB+kdA9Am3fL0ZhJhqBWR7TjRFxK2yh1/1qvXwMhxAWPSOlVK66VdzYVTQ+</HostId></Error>` as dtype `i32` at column '<?xml version=\"1.0\" encoding=\"UTF-8\"?>' (column number 1).\nThe current offset in the file is 39 bytes.\n\nYou might want to try:\n- increasing `infer_schema_length` (e.g. `infer_schema_length=10000`),\n- specifying correct dtype with the `dtypes` argument\n- setting `ignore_errors` to `True`,\n- adding `<Error><Code>AccessDenied</Code><Message>Access Denied</Message><RequestId>CRDE6SCDRTVQYSMR</RequestId><HostId>ojs4l0Kzt+RUdexslc+sddYYAik/5QO2om1N8qB+kdA9Am3fL0ZhJhqBWR7TjRFxK2yh1/1qvXwMhxAWPSOlVK66VdzYVTQ+</HostId></Error>` to the `null_values` list."
     ]
    }
   ],
   "source": [
    "# Please be kind to 17lands servers and don't overuse this. Will skip download if finds existing .gz files\n",
    "SetTools.download_game_data(set_abbreviation)\n",
    "SetTools.gz_to_parquet(set_abbreviation) # convert gzipped csv to parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63853ef-2edf-43a6-904a-e6cb1a55641e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed 577427 rows for decks in the same draft. 115865 decks remain.\n"
     ]
    }
   ],
   "source": [
    "df = SetTools.card2vec_preprocess(SetTools.parquet_path(set_abbreviation))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c21a0ef-282a-40e6-aaec-feeb7942d1ad",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model Training (Creating Card Embeddings)\n",
    "This relies on DeckCorpus, which is a generator that processes decks into word2vec compatible form before passing them to the model.\n",
    "* (converts from rows of integer card counts into lists of card names (strings). e.g., output decks will be in the format:\n",
    "    - [\"Mountain, \"Mountain\", \"Shock\", ... ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2e6871-e00c-47c5-b4d7-c250f59f9024",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shwes\\Projects\\ML\\mtg deckbuilding\\MTG-card2vec\\DeckCorpus.py:44: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  words = word * filtered_series[i]\n"
     ]
    }
   ],
   "source": [
    "# hyperparameters\n",
    "epochs = 5\n",
    "window_size = 40 # skipgram / CBOW window size\n",
    "vector_size = 256 # size of resulting card embeddings\n",
    "skipgram = 1 # uses CBOW if 0\n",
    "\n",
    "# Corpus (generator that yields decks)\n",
    "deck_corpus = DeckCorpus(data=df, shuffle=True)\n",
    "\n",
    "model = Word2Vec(sentences = deck_corpus,\n",
    "                 vector_size = vector_size,\n",
    "                 window = window_size,\n",
    "                 sg = skipgram,\n",
    "                 callbacks = [LossCallback('loss.log')], #Note that this is a gensim way of reporting training loss\n",
    "                 compute_loss = True,\n",
    "                 epochs = epochs,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1e9703-fcea-4508-baae-817b3314c674",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save embeddings as csv\n",
    "embed_dir = os.getcwd() + '/embeddings/' + set_abbreviation\n",
    "\n",
    "# Create the local directory if it doesn't exist\n",
    "if not os.path.exists(embed_dir): os.makedirs(embed_dir)\n",
    "\n",
    "pd.DataFrame(model.wv[model.wv.index_to_key], index=model.wv.index_to_key).to_csv(f'{embed_dir}/{set_abbreviation}_embeddings.csv')\n",
    "model.wv.save_word2vec_format(f'{embed_dir}/embed_gensim.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412c1497-7822-4252-a8bc-6c3d5d43076c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "model_dir = os.getcwd() + '/models/' + set_abbreviation\n",
    "\n",
    "# Create the local directory if it doesn't exist\n",
    "if not os.path.exists(model_dir): os.makedirs(model_dir)\n",
    "\n",
    "save_name = f'{set_abbreviation}.model'\n",
    "model.save(model_dir + '/' +save_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
